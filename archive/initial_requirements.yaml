version: 1
name: eu-ai-act-structural-preprocessor-step1
description: >
  Step 1 of the Trustworthy Project: add a structural preprocessing pipeline
  for the EU AI Act that extracts ONLY the physical structure of the regulation
  (recitals, chapters, sections, articles, paragraphs, points, annexes) into
  Pydantic models and ingests that structure deterministically into Neo4j.

context:
  project_root: trustworthy_project_v0
  existing_files:
    - .env
    - eu_ai_act.txt           # plain-text EU AI Act at repo root
    - config/neo4j_config.py  # existing Neo4j connection helper
    - agent_preprocess.py     # transcript preprocessor (DO NOT modify)
    - run_preprocess.py       # transcript runner (DO NOT modify)
    - ingest_preprocessed.py  # transcript ingestion (DO NOT modify)
    - models/                 # existing models (DO NOT break)
  notes:
    - This new work is for a *legal* preprocessing pipeline and must NOT break
      the existing financial transcript pipeline.
    - The user is doing a PhD on trustworthiness; code must be clean,
      conservative, and well documented.
    - No AI slop: avoid clever but opaque tricks. Favour clarity and simplicity.
    - The LLM agent must NOT write to Neo4j directly. Neo4j writes are handled
      by a separate deterministic ingestion module, as in the existing project.

  data_files:
    - path: eu_ai_act.txt
      # This is where the file lives in this chat environment; locally the user
      # will just have eu_ai_act.txt in the project root.
      url: /mnt/data/eu_ai_act.txt
      description: >
        Full plain-text of Regulation (EU) 2024/1689 â€“ the Artificial
        Intelligence Act ("EU AI Act"). Input to the structural preprocessor.

goals:
  - Create Pydantic models that represent the *physical structure* of a legal
    regulation document (recitals, chapters, sections, articles, paragraphs,
    points, annexes).
  - Implement a new preprocessing agent for the EU AI Act that:
      - takes raw text from eu_ai_act.txt + simple metadata,
      - outputs a single PreprocessedLegalDocument Pydantic object with
        structural elements only.
  - Implement a deterministic Neo4j ingestion module that:
      - takes PreprocessedLegalDocument,
      - creates Regulation, Recital, Chapter, Section, Article, Paragraph,
        Point, and Annex nodes,
      - creates HAS_* relationships between them,
      - does NOT call any LLMs.
  - Provide a simple runner script to:
      - read eu_ai_act.txt,
      - run the structural preprocessing agent,
      - ingest the resulting structure into Neo4j,
      - print a small summary (e.g. number of recitals, articles, annexes).

non_goals:
  - No semantic labelling yet:
      - Do NOT classify risk (high-risk, unacceptable, etc.).
      - Do NOT label actors, obligations, or HLEG principles.
  - Do NOT modify or break the existing financial transcript preprocessing code.
  - Do NOT add complex evaluation or testing frameworks yet; keep it minimal
    and readable, with docstrings and comments.

constraints:
  - The preprocessing agent must only extract *structure* that is explicitly
    present in the text:
      - Recitals: numbered (1), (2), (3), ...
      - Chapters: "CHAPTER I", "CHAPTER II", etc. with titles.
      - Sections (optional): "SECTION 1", "SECTION 2", etc. with titles.
      - Articles: "Article 1", "Article 2", etc. with titles.
      - Paragraphs: numbered 1., 2., 3., inside each article.
      - Points: lettered (a), (b), (c), inside paragraphs or directly under
        articles.
      - Annexes: "ANNEX I", "ANNEX II", etc. with titles and raw text.
  - Absolutely NO hallucinated structure:
      - Do not invent missing recitals or articles.
      - Do not re-number anything.
      - If a piece of structure is ambiguous, keep it as raw text at the
        nearest sensible level instead of guessing.
  - Code must be well documented with docstrings and comments explaining:
      - what each model represents,
      - how the agent is supposed to behave,
      - what the ingestion functions do.

tasks:

  - id: models-legal-structure
    description: >
      Add new Pydantic models under models/ for structural representation of
      legal documents (EU AI Act), without touching the existing financial
      models.
    changes:
      - path: models/legal_structure.py
        purpose: >
          Define structural models: Recital, Paragraph, Point, Article, Section,
          Chapter, Annex, PreprocessedLegalDocument.
        spec: |
          Create a new file models/legal_structure.py with:

          - Imports:
              - from typing import List, Optional
              - from pydantic import BaseModel, Field

          - Base models (all inherit from BaseModel, with docstrings):

            class Recital(BaseModel):
                """
                One recital of a regulation, from the 'Whereas' part.

                Example: Recital (1), (2), (3), etc.
                """
                number: int = Field(
                    description="Recital number as it appears in the text, e.g. 1 for '(1)'."
                )
                text: str = Field(
                    description="Full text of the recital, without the leading '(number)'."
                )

            class Point(BaseModel):
                """
                A lettered or numbered point inside a paragraph or directly under an article.
                Example: (a), (b), (c).
                """
                marker: str = Field(
                    description="Point marker as string, e.g. 'a', 'b', '1'."
                )
                text: str = Field(
                    description="Full text of the point, without the leading marker."
                )

            class Paragraph(BaseModel):
                """
                Numbered paragraph inside an article.
                Example: '1.', '2.'.
                """
                index: int = Field(
                    description="Paragraph number inside the article, e.g. 1 for '1.'."
                )
                text: str = Field(
                    description="Full text of the paragraph, excluding lettered points."
                )
                points: List[Point] = Field(
                    default_factory=list,
                    description="Optional list of lettered points within this paragraph."
                )

            class Article(BaseModel):
                """
                One article of the regulation.

                Contains a title and a list of numbered paragraphs (which may contain points).
                """
                number: int = Field(
                    description="Article number, e.g. 1 for 'Article 1'."
                )
                title: str = Field(
                    description="Article title as shown in the regulation."
                )
                paragraphs: List[Paragraph] = Field(
                    default_factory=list,
                    description="Ordered list of paragraphs in this article."
                )

            class Section(BaseModel):
                """
                Optional section within a chapter.
                Example: 'SECTION 1 - Classification rules'.
                """
                number: str = Field(
                    description="Section number as string (often roman or decimal), e.g. '1'."
                )
                title: str = Field(
                    description="Section title."
                )
                articles: List[Article] = Field(
                    default_factory=list,
                    description="Ordered list of articles in this section."
                )

            class Chapter(BaseModel):
                """
                One chapter of the regulation.
                Example: 'CHAPTER I - GENERAL PROVISIONS'.
                """
                number: str = Field(
                    description="Chapter number as string (e.g. 'I', 'II', 'III')."
                )
                title: str = Field(
                    description="Chapter title."
                )
                # Some chapters have sections; others have articles directly.
                sections: List[Section] = Field(
                    default_factory=list,
                    description="Optional sections within the chapter."
                )
                articles: List[Article] = Field(
                    default_factory=list,
                    description="Articles directly under this chapter (when there are no sections)."
                )

            class Annex(BaseModel):
                """
                Annex to the regulation.
                Example: 'ANNEX I', 'ANNEX II', etc.
                """
                number: str = Field(
                    description="Annex number as string, typically roman (e.g. 'I', 'II')."
                )
                title: str = Field(
                    description="Annex title."
                )
                raw_text: str = Field(
                    description="Full raw text of the annex body."
                )

            class PreprocessedLegalDocument(BaseModel):
                """
                Structural representation of a single legal document (here: the EU AI Act).

                This is the output of the structural preprocessing agent. It contains
                ONLY physical structure (recitals, chapters, articles, annexes), no
                semantic labels like risk categories or actors.
                """
                document_id: str = Field(
                    description="Stable identifier for this document, e.g. 'eu_ai_act_2024'."
                )
                official_title: str = Field(
                    description="Full official title of the regulation as printed."
                )
                short_title: Optional[str] = Field(
                    default=None,
                    description="Optional short/working title, e.g. 'EU AI Act'."
                )
                year: Optional[int] = Field(
                    default=None,
                    description="Year of adoption/publication, if known."
                )
                recitals: List[Recital] = Field(
                    default_factory=list,
                    description="Ordered list of recitals (Whereas (1), (2), ...)."
                )
                chapters: List[Chapter] = Field(
                    default_factory=list,
                    description="Ordered list of chapters."
                )
                annexes: List[Annex] = Field(
                    default_factory=list,
                    description="Ordered list of annexes."
                )

      - path: models/legal_preprocess.py
        purpose: >
          Define the dependency model used by the preprocessing agent for the
          EU AI Act (simple document metadata).
        spec: |
          Create a new file models/legal_preprocess.py with:

          - Imports:
              - from pydantic import BaseModel, Field

          - Define a dependency model similar in spirit to PreprocessDeps but
            for legal documents:

            class LegalPreprocessDeps(BaseModel):
                """
                Deterministic metadata for legal document preprocessing.

                All of these values are provided by the caller and must be echoed
                back by the agent. The agent MUST NOT infer or change them.
                """
                document_id: str = Field(
                    description="Stable identifier for this legal document, e.g. 'eu_ai_act_2024'."
                )
                source_file: str = Field(
                    description="Path to the source text file, e.g. 'eu_ai_act.txt'."
                )
                jurisdiction: str = Field(
                    default="EU",
                    description="Jurisdiction of the legal instrument, default 'EU'."
                )
                instrument_type: str = Field(
                    default="Regulation",
                    description="Type of legal instrument, e.g. 'Regulation', 'Directive'."
                )


  - id: agent-preprocess-legal
    description: >
      Implement a new PydanticAI agent that parses eu_ai_act.txt and outputs a
      PreprocessedLegalDocument, using only structural cues in the text.
    changes:
      - path: agent_preprocess_eu_ai_act.py
        purpose: >
          Define the structural preprocessing agent for the EU AI Act, mirroring
          the pattern of agent_preprocess.py but operating on legal structure.
        spec: |
          Create agent_preprocess_eu_ai_act.py at project root with:

          - Imports:
              - from dotenv import load_dotenv
              - from pydantic_ai import Agent
              - from pydantic_ai.models.openai import OpenAIChatModel
              - from models.legal_structure import PreprocessedLegalDocument
              - from models.legal_preprocess import LegalPreprocessDeps

          - Load environment variables with load_dotenv() at top-level (same pattern as existing agent).

          - Configure the model:

            model = OpenAIChatModel(
                model_name="gpt-4o-mini",
            )

          - Define the agent:

            preprocess_legal_agent = Agent[LegalPreprocessDeps, PreprocessedLegalDocument](
                model,
                deps_type=LegalPreprocessDeps,
                output_type=PreprocessedLegalDocument,
                instructions=\"\"\"You are a structural parser for EU regulations.

            Your task is to analyze the full plain text of the EU Artificial Intelligence Act
            (Regulation (EU) 2024/1689) and extract ONLY its physical structure into a
            PreprocessedLegalDocument.

            INPUT:
              - Deterministic metadata (deps):
                  - document_id
                  - source_file
                  - jurisdiction
                  - instrument_type
              - Prompt text containing:
                  - The full plain text of the regulation (eu_ai_act.txt)
                  - The official title of the regulation
                  - Any additional comments from the caller (ignore for structure).

            OUTPUT:
              - A PreprocessedLegalDocument with:
                  - document_id: echoed exactly from deps
                  - official_title: taken from the provided metadata/prompt, not invented
                  - short_title: 'EU AI Act'
                  - year: 2024
                  - recitals: list of Recital objects
                  - chapters: list of Chapter objects (with sections and/or articles)
                  - annexes: list of Annex objects

            CRITICAL RULES (TRUSTWORTHINESS):

            1. NO HALLUCINATED STRUCTURE
               - Do NOT invent recitals, chapters, articles, or annexes.
               - Use only what is explicitly present in the text.
               - If something is ambiguous, keep it as raw text at the nearest sensible level,
                 do NOT guess.

            2. NUMBERING
               - Recitals: parse patterns like '(1)', '(2)', '(3)' in the 'Whereas' section.
               - Chapters: parse patterns like 'CHAPTER I', 'CHAPTER II', etc.
               - Sections: parse patterns like 'SECTION 1', 'SECTION 2', etc., *only if*
                 clearly present. If not present in a chapter, leave sections empty and
                 put articles directly under the chapter.
               - Articles: parse 'Article 1', 'Article 2', etc., with titles.
               - Paragraphs: parse numbered paragraphs '1.', '2.', '3.' inside each article.
               - Points: parse lettered points '(a)', '(b)', '(c)' within paragraphs or
                 directly under an article.

            3. TEXT HANDLING
               - For each structural element, include the full text associated with it:
                   - Recital.text: text after '(n)' until the next recital or the end of recitals.
                   - Article.title: the title line after 'Article N'.
                   - Paragraph.text: the paragraph's main body, excluding lettered points.
                   - Point.text: the text after '(a)', '(b)', etc., up to the next point.
                   - Annex.raw_text: everything in the annex body after the annex heading.
               - Preserve the original wording and ordering as closely as possible.
               - Do NOT rewrite or summarise; this is structural extraction, not editing.

            4. METADATA HANDLING
               - Echo document_id exactly as provided in deps.
               - Set official_title based on the title string provided in the prompt.
               - Set short_title to 'EU AI Act'.
               - Set year to 2024.
               - Echo jurisdiction and instrument_type only if needed in the output
                 (they are primarily for future extensions; do not invent new values).

            5. OUTPUT FORMAT
               - Return a single PreprocessedLegalDocument instance.
               - Do NOT include any semantic labels (no 'high-risk', 'unacceptable',
                 'HLEG principles', actors, or obligations).
               - Do NOT include any Neo4j or database logic.

            Your job is to convert free-form regulation text into a structured,
            lossless, and conservative representation of its physical layout.
            \"\"\",
            )

  - id: runner-legal-preprocess
    description: >
      Add a runner script that reads eu_ai_act.txt, calls preprocess_legal_agent,
      prints a small summary, and optionally calls the deterministic Neo4j ingestion.
    changes:
      - path: run_preprocess_eu_ai_act.py
        purpose: >
          Provide an entry point similar to run_preprocess.py but for the EU AI Act
          legal structure.
        spec: |
          Create run_preprocess_eu_ai_act.py at project root with:

          - Imports:
              - import asyncio
              - from pathlib import Path
              - from models.legal_structure import PreprocessedLegalDocument
              - from models.legal_preprocess import LegalPreprocessDeps
              - from agent_preprocess_eu_ai_act import preprocess_legal_agent
              - from ingest_preprocessed_legal import ingest_preprocessed_legal_document

          - A helper function to read the raw text:

            def read_eu_ai_act_text(file_path: Path) -> str:
                """
                Read the full EU AI Act text from a plain-text file.

                Args:
                    file_path: Path to 'eu_ai_act.txt'

                Returns:
                    The full text as a string.

                Raises:
                    FileNotFoundError: if the file is missing
                    ValueError: if the file is empty
                """
                if not file_path.exists():
                    raise FileNotFoundError(f"File not found: {file_path}")
                text = file_path.read_text(encoding="utf-8")
                if not text.strip():
                    raise ValueError(f"Empty text in {file_path}")
                return text

          - An async function to run the preprocessing:

            async def preprocess_eu_ai_act() -> PreprocessedLegalDocument:
                DOCUMENT_ID = "eu_ai_act_2024"
                SOURCE_FILE = "eu_ai_act.txt"
                OFFICIAL_TITLE = (
                    "Regulation (EU) 2024/1689 of the European Parliament and of "
                    "the Council ... (Artificial Intelligence Act)"
                )

                file_path = Path(SOURCE_FILE)
                raw_text = read_eu_ai_act_text(file_path)

                deps = LegalPreprocessDeps(
                    document_id=DOCUMENT_ID,
                    source_file=SOURCE_FILE,
                    jurisdiction="EU",
                    instrument_type="Regulation",
                )

                # Build a clear prompt containing title + raw text
                prompt = (
                    f"Official title: {OFFICIAL_TITLE}\n\n"
                    f"Below is the full plain text of the EU AI Act:\n\n"
                    f"{raw_text}"
                )

                result = await preprocess_legal_agent.run(prompt, deps=deps)
                preprocessed: PreprocessedLegalDocument = result.output
                return preprocessed

          - A synchronous main() that:
              - prints basic info,
              - runs preprocess_eu_ai_act(),
              - prints a summary: number of recitals, chapters, articles, annexes,
              - calls ingest_preprocessed_legal_document(preprocessed, raw_text).

          - __main__ guard calling asyncio.run(main()) and printing friendly messages.


  - id: neo4j-ingestion-legal
    description: >
      Implement deterministic Neo4j ingestion for PreprocessedLegalDocument,
      creating legal structure nodes and relationships, with no LLM calls.
    changes:
      - path: ingest_preprocessed_legal.py
        purpose: >
          Mirror ingest_preprocessed.py but for legal document structure instead
          of transcript persons/sentences.
        spec: |
          Create ingest_preprocessed_legal.py at project root with:

          - Imports:
              - from typing import Optional
              - from neo4j import Driver
              - from models.legal_structure import PreprocessedLegalDocument
              - from config.neo4j_config import get_neo4j_driver

          - High-level behaviour:

            def ingest_preprocessed_legal_document(
                preprocessed: PreprocessedLegalDocument,
            ) -> None:
                """
                Deterministically write a PreprocessedLegalDocument to Neo4j.

                Graph schema (initial, simple version):

                  (r:Regulation {document_id})
                    -[:HAS_RECITAL]-> (rec:Recital {document_id, number})
                    -[:HAS_CHAPTER]-> (ch:Chapter {document_id, number})
                    -[:HAS_ANNEX]-> (ax:Annex {document_id, number})

                  (ch)-[:HAS_SECTION]->(sec:Section {document_id, number})
                  (ch)-[:HAS_ARTICLE]->(art:Article {document_id, number})
                  (sec)-[:HAS_ARTICLE]->(art:Article {document_id, number})

                  (art)-[:HAS_PARAGRAPH]->(par:Paragraph {document_id, article_number, index})
                  (par)-[:HAS_POINT]->(pt:Point {document_id, article_number, paragraph_index, marker})

                This ingestion must:
                  - NOT call any LLMs.
                  - Use MERGE so re-running is idempotent at the node/relationship level.
                  - Be deterministic given the same PreprocessedLegalDocument.

                For now, do NOT delete existing nodes; we keep it simple (future
                cleanup logic can be added later).
                """

          - Implement helper functions similar in style to ingest_preprocessed.py:
              - _merge_regulation_node(driver, preprocessed)
              - _merge_recitals(driver, preprocessed)
              - _merge_chapters_and_articles(driver, preprocessed)
              - _merge_annexes(driver, preprocessed)

          - Use simple, predictable IDs:
              - Regulation node key: (Regulation {document_id: preprocessed.document_id})
              - Recital node key: (Recital {document_id, number})
              - Chapter node key: (Chapter {document_id, number})
              - Section node key: (Section {document_id, number})
              - Article node key: (Article {document_id, number})
              - Paragraph node key: (Paragraph {document_id, article_number, index})
              - Point node key: (Point {document_id, article_number, paragraph_index, marker})

          - For each helper:
              - Construct a Cypher query with UNWIND where appropriate to batch inserts.
              - Set text fields on nodes (e.g. rec.text, ch.title, art.title, par.text, pt.text, ax.raw_text).
              - Create appropriate HAS_* relationships using MERGE.

acceptance_criteria:
  - Code compiles (mypy/ruff not required, but imports must resolve and Python
    should run without syntax errors).
  - Running python run_preprocess_eu_ai_act.py with a valid eu_ai_act.txt:
      - Reads the text successfully.
      - Calls the preprocessing agent without exceptions.
      - Prints a summary like:
          - "Recitals: N"
          - "Chapters: C"
          - "Articles (total across chapters): A"
          - "Annexes: X"
      - Writes nodes to Neo4j following the described schema.
  - The existing financial transcript pipeline (agent_preprocess.py,
    run_preprocess.py, ingest_preprocessed.py) still runs exactly as before and
    is not modified by this step.
  - All new models and functions have docstrings explaining
