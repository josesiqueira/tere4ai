version: 1
tasks:
  - description: |
      Add an AI HLEG preprocessing pipeline that:
        - Reads the AI HLEG guidelines from data/ai_hleg.txt
        - Uses an LLM (gpt-5-nano) to extract the seven requirements of Trustworthy AI
        - Produces structured Pydantic models
        - Ingests them deterministically into Neo4j (no LLM in ingestion)
        - Includes minimal sanity checks (e.g. exactly seven requirements)

      This should mirror the style and trustworthiness principles of the EU AI Act preprocessor:
        - Deterministic metadata via deps
        - LLM-only semantics, Python-only for orchestration and Neo4j writes
        - No guessing of document IDs or requirement list beyond what is explicitly defined
    changes:
      - path: models/ai_hleg.py
        type: create
        content: |
          """
          Pydantic Models for AI HLEG "Ethics Guidelines for Trustworthy AI"

          This module defines the structural representation of the
          seven key requirements of Trustworthy AI from the AI HLEG
          guidelines.

          IMPORTANT TRUSTWORTHINESS PRINCIPLES:

            - The seven requirements are a CLOSED, CANONICAL set.
              The LLM must not invent additional requirements.

            - Each requirement has:
                * a stable machine id (snake_case)
                * canonical name (as in the guidelines)
                * canonical order (1..7)
                * a short description (faithful summary)
                * a full_text field (substantial excerpt from the guidelines)

            - This module does NOT contain any logic for mapping incidents,
              EU AI Act obligations, or other semantics. It is purely
              about representing the HLEG requirements structurally.

          This mirrors the philosophy of the EU AI Act structural models:
          we first extract structure in a trustworthy way, and only later
          add semantic layers (e.g. risk mapping, incident alignment).
          """

          from __future__ import annotations

          from typing import List, Optional
          from pydantic import BaseModel, Field


          class HlegRequirement(BaseModel):
              """
              One of the seven requirements of Trustworthy AI from the AI HLEG guidelines.

              Example:
                - id: "human_agency_and_oversight"
                - order: 1
                - name: "Human agency and oversight"
              """
              id: str = Field(
                  description=(
                      "Stable machine identifier for this requirement, "
                      "e.g. 'human_agency_and_oversight'. "
                      "Must come from a CLOSED, predefined list."
                  )
              )
              order: int = Field(
                  description="Canonical order of the requirement (1..7)."
              )
              name: str = Field(
                  description="Official name of the requirement as used in the guidelines."
              )
              short_description: str = Field(
                  description=(
                      "Short summary (1–3 sentences) of the requirement, "
                      "faithfully derived from the guidelines."
                  )
              )
              full_text: str = Field(
                  description=(
                      "Substantial excerpt of the requirement's section from the guidelines. "
                      "Should be grounded in the original text (verbatim or lightly cleaned), "
                      "NOT invented."
                  )
              )
              related_principles: List[str] = Field(
                  default_factory=list,
                  description=(
                      "Optional list of HLEG ethical principle IDs that underpin this requirement, "
                      "e.g. ['respect_for_human_autonomy', 'prevention_of_harm']."
                  ),
              )
              tags: List[str] = Field(
                  default_factory=list,
                  description=(
                      "Optional free-form keywords for querying/grouping, "
                      "e.g. ['safety', 'robustness', 'non-discrimination']."
                  ),
              )


          class HlegStructuredDoc(BaseModel):
              """
              Structural representation of the AI HLEG guidelines at the level of
              the seven requirements of Trustworthy AI.

              This is the output of the AI HLEG preprocessing agent.
              It is intentionally minimal: we only capture what we need
              to later connect to EU AI Act obligations and incidents.
              """
              document_id: str = Field(
                  description=(
                      "Stable identifier for this HLEG document, e.g. 'ai_hleg_2019'. "
                      "Provided deterministically by the caller, NOT inferred by the LLM."
                  )
              )
              official_title: str = Field(
                  description="Full official title of the guidelines."
              )
              short_title: Optional[str] = Field(
                  default=None,
                  description="Optional short title, e.g. 'AI HLEG Ethics Guidelines'."
              )
              year: int = Field(
                  description="Year of publication of the guidelines, e.g. 2019."
              )

              requirements: List[HlegRequirement] = Field(
                  default_factory=list,
                  description="List of the seven requirements of Trustworthy AI."
              )

      - path: models/hleg_preprocess.py
        type: create
        content: |
          """
          Dependency Model for AI HLEG Preprocessing

          This module defines the input dependency model used by the AI HLEG
          preprocessing agent.

          Key principle: ALL metadata is deterministic and provided by the caller.
          The LLM agent MUST NOT infer or change these values.

          This mirrors the approach used for the EU AI Act preprocessing.
          """

          from pydantic import BaseModel, Field


          class HlegPreprocessDeps(BaseModel):
              """
              Deterministic metadata for AI HLEG document preprocessing.

              All of these values are provided by the caller and must be echoed
              back by the agent. The agent MUST NOT infer or change them.
              """
              document_id: str = Field(
                  description="Stable identifier for this HLEG document, e.g. 'ai_hleg_2019'."
              )
              source_file: str = Field(
                  description="Path to the source text file, e.g. 'data/ai_hleg.txt'."
              )
              jurisdiction: str = Field(
                  default="EU",
                  description="Jurisdiction of the guidelines, default 'EU'."
              )
              instrument_type: str = Field(
                  default="Guidelines",
                  description="Type of instrument, e.g. 'Guidelines'."
              )
              year: int = Field(
                  default=2019,
                  description="Year of publication of the guidelines."
              )

      - path: agent_hleg_preprocess.py
        type: create
        content: |
          """
          AI HLEG Pre-processing Agent

          This module defines a PydanticAI agent that takes the raw text of the
          AI HLEG "Ethics Guidelines for Trustworthy AI" and extracts the
          seven requirements of Trustworthy AI in a structured form.

          TRUSTWORTHINESS PRINCIPLES:

            - The agent ONLY performs semantic extraction.
              It does NOT write to Neo4j or perform any side effects.

            - All deterministic metadata (document_id, source_file, year, etc.)
              is provided via HlegPreprocessDeps and MUST be echoed back exactly.

            - The set of requirements is CLOSED and CANONICAL:
              exactly seven requirements, with predefined IDs and names.
              The agent must not invent new requirements.

            - The 'full_text' for each requirement must be grounded in the
              original guidelines text (verbatim or lightly cleaned), not invented.
          """

          from dotenv import load_dotenv
          from pydantic_ai import Agent
          from pydantic_ai.models.openai import OpenAIChatModel

          from models.ai_hleg import HlegStructuredDoc
          from models.hleg_preprocess import HlegPreprocessDeps

          # Load environment variables from .env file (for OPENAI_API_KEY)
          load_dotenv()

          # ============================================================================
          # LLM Model Configuration
          # ============================================================================

          # Use GPT-5-nano for high-context, cost-effective preprocessing
          model = OpenAIChatModel(
              model_name="gpt-5-nano",
          )


          # ============================================================================
          # Preprocessing Agent Definition
          # ============================================================================

          hleg_preprocess_agent = Agent[HlegPreprocessDeps, HlegStructuredDoc](
              model,
              deps_type=HlegPreprocessDeps,
              output_type=HlegStructuredDoc,
              instructions="""
              You are a preprocessing specialist for the AI HLEG 'Ethics Guidelines
              for Trustworthy AI'.

              Your task is to read the ENTIRE guidelines text and extract a
              structured representation of the SEVEN requirements of Trustworthy AI.

              INPUT:
                - Full plain text of the AI HLEG guidelines
                - Deterministic metadata via deps:
                    * document_id (e.g. 'ai_hleg_2019')
                    * source_file (e.g. 'data/ai_hleg.txt')
                    * jurisdiction (e.g. 'EU')
                    * instrument_type (e.g. 'Guidelines')
                    * year (e.g. 2019)

              OUTPUT:
                - One HlegStructuredDoc with:
                    * document_id, official_title, short_title, year
                    * requirements: exactly SEVEN HlegRequirement objects

              CRITICAL RULES:

              1. METADATA HANDLING
                 - Echo document_id, year, etc. exactly from deps.
                 - Do NOT infer or change these values.
                 - If the official title appears in the text, copy it faithfully
                   into 'official_title'. You may set 'short_title' to a concise
                   variant like 'AI HLEG Ethics Guidelines'.

              2. CLOSED SET OF REQUIREMENTS
                 The seven requirements of Trustworthy AI are:

                   1) Human agency and oversight
                   2) Technical robustness and safety
                   3) Privacy and data governance
                   4) Transparency
                   5) Diversity, non-discrimination and fairness
                   6) Societal and environmental well-being
                   7) Accountability

                 You MUST:
                   - Extract exactly these seven requirements, no more, no less.
                   - Use the following stable IDs for the 'id' field:

                     - human_agency_and_oversight
                     - technical_robustness_and_safety
                     - privacy_and_data_governance
                     - transparency
                     - diversity_non_discrimination_and_fairness
                     - societal_and_environmental_well_being
                     - accountability

                   - The 'name' field must match the official wording in the guidelines
                     as closely as possible (minor punctuation differences are OK).

              3. SHORT_DESCRIPTION vs FULL_TEXT
                 - short_description:
                     * 1–3 sentences summarising the requirement.
                     * Must be faithful to the guidelines and NOT speculative.
                     * You may paraphrase as long as the meaning is preserved.

                 - full_text:
                     * Use a substantial excerpt from the guidelines section that
                       introduces and explains the requirement.
                     * You may remove line breaks, bullets, and minor formatting,
                       but must NOT invent content.
                     * The goal is to have a grounded text we can later show to users
                       and use for alignment with EU AI Act and incidents.

              4. RELATED PRINCIPLES
                 - Optionally, you may fill 'related_principles' with IDs of the
                   HLEG ethical principles that underpin the requirement.
                 - These principle IDs (for future expansion) should be:

                     - respect_for_human_autonomy
                     - prevention_of_harm
                     - fairness
                     - explicability

                 - If you're not sure, leave 'related_principles' empty.
                   Do NOT invent new principle IDs.

              5. TAGS
                 - 'tags' is optional. You may provide 0–5 concise keywords
                   per requirement to help future querying, e.g.:

                     - For technical robustness and safety:
                         ['safety', 'robustness', 'reliability']
                     - For diversity, non-discrimination and fairness:
                         ['bias', 'non-discrimination']

                 - Tags must be grounded in the content of the requirement.

              6. COMPLETENESS & FAITHFULNESS
                 - You must extract ALL seven requirements.
                 - Do NOT drop any requirement.
                 - Do NOT add extra requirements beyond the canonical seven.
                 - All text fields must be grounded in the original document.

              7. OUTPUT STYLE
                 - Produce a single HlegStructuredDoc object.
                 - No extra commentary or free-form text outside the structured output.
                 - This output will be validated by Pydantic; follow the schema precisely.
              """,
          )

      - path: ingest_hleg.py
        type: create
        content: |
          """
          Deterministic Neo4j Ingestion for AI HLEG Requirements

          This module takes a HlegStructuredDoc (output from agent_hleg_preprocess.py)
          and writes it to Neo4j.

          Key principles:
            - NO LLM calls here - all data comes from HlegStructuredDoc.
            - Deterministic and idempotent:
                * Uses MERGE for HLEG document node and requirement nodes.
                * MERGE for relationships to avoid duplicates.
            - Simple, explicit graph schema:

                (h:HLEG {document_id})
                  -[:HAS_REQUIREMENT]->
                (r:HLEGRequirement {id})

          This mirrors the deterministic ingestion pattern used for the EU AI Act.
          """

          from typing import List

          from neo4j import Driver
          from models.ai_hleg import HlegStructuredDoc, HlegRequirement
          from config.neo4j_config import get_neo4j_driver


          def ingest_hleg_document(doc: HlegStructuredDoc) -> None:
              """
              Ingest a HlegStructuredDoc into Neo4j in a deterministic way.

              Graph schema:

                - (h:HLEG {document_id})
                    * h.official_title
                    * h.short_title
                    * h.year

                - (r:HLEGRequirement {id})
                    * r.order
                    * r.name
                    * r.short_description
                    * r.full_text
                    * r.related_principles (array)
                    * r.tags (array)

                - (h)-[:HAS_REQUIREMENT]->(r)

              Args:
                  doc: The HlegStructuredDoc produced by the preprocessing agent.
              """
              with get_neo4j_driver() as driver:
                  _create_hleg_document_and_requirements(driver, doc)

              print(f"✓ Ingested HLEG document '{doc.document_id}' to Neo4j")
              print(f"  - Requirements: {len(doc.requirements)}")


          def _create_hleg_document_and_requirements(driver: Driver, doc: HlegStructuredDoc) -> None:
              """
              Create or merge the HLEG document node and its requirements.
              """
              # Step 1: Create/merge HLEG document node
              cypher_doc = """
              MERGE (h:HLEG {document_id: $document_id})
              SET h.official_title = $official_title,
                  h.short_title    = $short_title,
                  h.year           = $year
              """
              driver.execute_query(
                  cypher_doc,
                  document_id=doc.document_id,
                  official_title=doc.official_title,
                  short_title=doc.short_title,
                  year=doc.year,
              )

              # Step 2: Create/merge requirement nodes and relationships
              cypher_req = """
              MATCH (h:HLEG {document_id: $document_id})
              UNWIND $requirements AS req
              MERGE (r:HLEGRequirement {id: req.id})
              SET r.order             = req.order,
                  r.name              = req.name,
                  r.short_description = req.short_description,
                  r.full_text         = req.full_text,
                  r.related_principles = req.related_principles,
                  r.tags               = req.tags
              MERGE (h)-[:HAS_REQUIREMENT]->(r)
              """

              requirements_data: List[dict] = [
                  {
                      "id": r.id,
                      "order": r.order,
                      "name": r.name,
                      "short_description": r.short_description,
                      "full_text": r.full_text,
                      "related_principles": r.related_principles,
                      "tags": r.tags,
                  }
                  for r in doc.requirements
              ]

              driver.execute_query(
                  cypher_req,
                  document_id=doc.document_id,
                  requirements=requirements_data,
              )

      - path: run_preprocess_ai_hleg.py
        type: create
        content: |
          """
          Step: Preprocess AI HLEG Guidelines & Ingest Requirements into Neo4j

          This script:
            1. Reads the AI HLEG guidelines text from data/ai_hleg.txt
            2. Uses the hleg_preprocess_agent (GPT-5-nano) to extract the
               seven requirements of Trustworthy AI
            3. Performs a basic sanity check (exactly 7 requirements)
            4. Ingests the structured result into Neo4j

          This mirrors the design of the EU AI Act preprocessing pipeline:
            - LLM-only for semantic extraction
            - Deterministic metadata via deps
            - Deterministic Neo4j writes via ingest_hleg.py
          """

          import asyncio
          from pathlib import Path

          from dotenv import load_dotenv

          from agent_hleg_preprocess import hleg_preprocess_agent
          from models.hleg_preprocess import HlegPreprocessDeps
          from models.ai_hleg import HlegStructuredDoc
          from ingest_hleg import ingest_hleg_document
          from config.neo4j_config import verify_connection


          # Load environment variables from .env file (for OPENAI_API_KEY, Neo4j config)
          load_dotenv()


          async def preprocess_ai_hleg() -> HlegStructuredDoc:
              """
              Preprocess the AI HLEG guidelines into a HlegStructuredDoc.
              """
              # Configuration for this document
              DOCUMENT_ID = "ai_hleg_2019"
              SOURCE_FILE = "data/ai_hleg.txt"
              YEAR = 2019

              file_path = Path(SOURCE_FILE)
              if not file_path.exists():
                  raise FileNotFoundError(
                      f"AI HLEG source file not found: {SOURCE_FILE} "
                      "(expected at project_root/data/ai_hleg.txt)"
                  )

              raw_text = file_path.read_text(encoding="utf-8")

              # Build a clear prompt
              prompt = (
                  "You will receive the full text of the AI HLEG 'Ethics Guidelines for Trustworthy AI'.\n"
                  "Your task is to extract the seven requirements of Trustworthy AI as "
                  "a structured HlegStructuredDoc.\n\n"
                  "Full text:\n"
                  f"{raw_text}"
              )

              deps = HlegPreprocessDeps(
                  document_id=DOCUMENT_ID,
                  source_file=SOURCE_FILE,
                  year=YEAR,
              )

              result = await hleg_preprocess_agent.run(prompt, deps=deps)
              return result.output


          async def main() -> None:
              """
              Main entrypoint for AI HLEG preprocessing and ingestion.
              """
              print("Prerequisites:")
              print("  ✓ OPENAI_API_KEY in .env file")
              print("  ✓ Neo4j running and reachable (URI/creds from .env)")
              print("  ✓ data/ai_hleg.txt present\n")

              # Verify Neo4j connection (optional but helpful for debugging)
              if not verify_connection():
                  print("❌ Neo4j connection failed. Please check config.neo4j_config and Docker.")
                  return
              else:
                  print("✓ Neo4j connection verified.\n")

              print("=" * 70)
              print("AI HLEG - PREPROCESSING & INGESTION")
              print("=" * 70)
              print(
                  "This script extracts the seven requirements of Trustworthy AI\n"
                  "from the AI HLEG 'Ethics Guidelines for Trustworthy AI' and "
                  "ingests them into Neo4j.\n"
              )

              print("[1/2] Running AI HLEG preprocessing agent (GPT-5-nano)...\n")

              try:
                  doc = await preprocess_ai_hleg()
              except FileNotFoundError as e:
                  print(f"❌ {e}")
                  return
              except Exception as e:
                  print(f"❌ Preprocessing failed: {e}")
                  return

              # Basic sanity check: we expect exactly 7 requirements
              num_reqs = len(doc.requirements)
              print(f"✓ Preprocessing completed. Found {num_reqs} requirements.\n")

              if num_reqs != 7:
                  print("⚠️  Sanity check FAILED: expected 7 requirements, "
                        f"but got {num_reqs}.")
                  print("    For trustworthiness, we will NOT ingest this result.")
                  print("    Please inspect the agent output and instructions.")
                  return

              print("[2/2] Ingesting HLEG requirements into Neo4j...\n")
              try:
                  ingest_hleg_document(doc)
              except Exception as e:
                  print(f"❌ Ingestion failed: {e}")
                  return

              print()
              print("=" * 70)
              print("✓ AI HLEG PREPROCESSING & INGESTION COMPLETE")
              print("=" * 70)
              print()
              print("You can now explore the graph in Neo4j, e.g.:")
              print("  MATCH (h:HLEG)-[:HAS_REQUIREMENT]->(r:HLEGRequirement)")
              print("  RETURN h, r;")
              print()
              print("These HLEGRequirement nodes can later be linked to:")
              print("  - EU AI Act obligations (articles, annexes)")
              print("  - Incident assessments")
              print("to support your PhD research on trustworthy AI systems.")


          if __name__ == "__main__":
              asyncio.run(main())
