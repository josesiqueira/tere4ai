version: 1
tasks:
  - description: |
      Enhance the AI HLEG modeling and ingestion to support RequirementSubtopics
      (e.g. "Sustainable and environmentally friendly AI", "Social impact",
      "Society and Democracy") under each HLEG requirement.

      Goal:
        - Introduce a HlegRequirementSubtopic model in Pydantic.
        - Attach subtopics to HlegRequirement as a `subtopics` list.
        - Instruct the hleg_preprocess_agent to optionally extract subtopics
          when the guidelines contain titled sub-headings under a requirement.
        - Ingest subtopics into Neo4j as separate nodes linked to their parent
          requirement via :HAS_SUBTOPIC.

      This must:
        - Preserve the canonical seven HLEG requirements (no new requirements).
        - Keep subtopics clearly subordinate to their requirement, not new top-level requirements.
        - Maintain the trustworthiness story: LLM does semantic extraction;
          Python does deterministic, idempotent Neo4j writes.
    changes:
      - path: models/ai_hleg.py
        type: update
        content: |
          """
          Pydantic Models for AI HLEG "Ethics Guidelines for Trustworthy AI"

          This module defines the structural representation of the
          seven key requirements of Trustworthy AI from the AI HLEG
          guidelines, plus optional RequirementSubtopics under each
          requirement.

          IMPORTANT TRUSTWORTHINESS PRINCIPLES:

            - The seven requirements are a CLOSED, CANONICAL set.
              The LLM must not invent additional requirements.

            - Each requirement has:
                * a stable machine id (snake_case)
                * canonical name (as in the guidelines)
                * canonical order (1..7)
                * a short description (faithful summary)
                * a full_text field (substantial excerpt from the guidelines)
                * an optional list of RequirementSubtopics

            - RequirementSubtopics are titled sub-sections under a single
              requirement (e.g. "Sustainable and environmentally friendly AI",
              "Social impact", "Society and Democracy" under societal and
              environmental well-being). They are NOT new requirements,
              but aspects/themes of one requirement.

            - This module does NOT contain any logic for mapping incidents,
              EU AI Act obligations, or other semantics. It is purely
              about representing the HLEG structure.

          This mirrors the philosophy of the EU AI Act structural models:
          we first extract structure in a trustworthy way, and only later
          add semantic layers (e.g. risk mapping, incident alignment).
          """

          from __future__ import annotations

          from typing import List, Optional
          from pydantic import BaseModel, Field


          class HlegRequirementSubtopic(BaseModel):
              """
              A titled subtopic under a single HLEG requirement.

              Example (under 'Societal and environmental well-being'):
                - label: "Sustainable and environmentally friendly AI"
                - description: the full paragraph(s) under that heading.

              These are NOT additional requirements. They are aspects/themes
              of one canonical requirement, useful for more fine-grained
              linking (e.g. to incidents, EU AI Act provisions).
              """
              id: str = Field(
                  description=(
                      "Stable machine identifier for this subtopic, e.g. "
                      "'societal_env_wellbeing_sustainable_ai'. Must be unique "
                      "within the document and grounded in the heading."
                  )
              )
              label: str = Field(
                  description=(
                      "Short human-readable label for the subtopic, usually the "
                      "titled heading in the guidelines, e.g. "
                      "'Sustainable and environmentally friendly AI'."
                  )
              )
              description: str = Field(
                  description=(
                      "Full text of the subtopic (the paragraph(s) under the heading), "
                      "cleaned for whitespace but grounded in the original document."
                  )
              )


          class HlegRequirement(BaseModel):
              """
              One of the seven requirements of Trustworthy AI from the AI HLEG guidelines.

              Example:
                - id: "human_agency_and_oversight"
                - order: 1
                - name: "Human agency and oversight"
              """
              id: str = Field(
                  description=(
                      "Stable machine identifier for this requirement, "
                      "e.g. 'human_agency_and_oversight'. "
                      "Must come from a CLOSED, predefined list."
                  )
              )
              order: int = Field(
                  description="Canonical order of the requirement (1..7)."
              )
              name: str = Field(
                  description="Official name of the requirement as used in the guidelines."
              )
              short_description: str = Field(
                  description=(
                      "Short summary (1–3 sentences) of the requirement, "
                      "faithfully derived from the guidelines."
                  )
              )
              full_text: str = Field(
                  description=(
                      "Substantial excerpt of the requirement's section from the guidelines. "
                      "Should be grounded in the original text (verbatim or lightly cleaned), "
                      "NOT invented."
                  )
              )
              related_principles: List[str] = Field(
                  default_factory=list,
                  description=(
                      "Optional list of HLEG ethical principle IDs that underpin this requirement, "
                      "e.g. ['respect_for_human_autonomy', 'prevention_of_harm']."
                  ),
              )
              tags: List[str] = Field(
                  default_factory=list,
                  description=(
                      "Optional free-form keywords for querying/grouping, "
                      "e.g. ['safety', 'robustness', 'non-discrimination']."
                  ),
              )
              subtopics: List[HlegRequirementSubtopic] = Field(
                  default_factory=list,
                  description=(
                      "Optional list of titled RequirementSubtopics under this requirement, "
                      "e.g. 'Sustainable and environmentally friendly AI', "
                      "'Social impact', 'Society and Democracy' under "
                      "societal and environmental well-being."
                  ),
              )


          class HlegStructuredDoc(BaseModel):
              """
              Structural representation of the AI HLEG guidelines at the level of
              the seven requirements of Trustworthy AI, plus optional subtopics.

              This is the output of the AI HLEG preprocessing agent.
              It is intentionally minimal: we only capture what we need
              to later connect to EU AI Act obligations and incidents.
              """
              document_id: str = Field(
                  description=(
                      "Stable identifier for this HLEG document, e.g. 'ai_hleg_2019'. "
                      "Provided deterministically by the caller, NOT inferred by the LLM."
                  )
              )
              official_title: str = Field(
                  description="Full official title of the guidelines."
              )
              short_title: Optional[str] = Field(
                  default=None,
                  description="Optional short title, e.g. 'AI HLEG Ethics Guidelines'."
              )
              year: int = Field(
                  description="Year of publication of the guidelines, e.g. 2019."
              )

              requirements: List[HlegRequirement] = Field(
                  default_factory=list,
                  description="List of the seven requirements of Trustworthy AI."
              )

      - path: agent_hleg_preprocess.py
        type: update
        content: |
          """
          AI HLEG Pre-processing Agent

          This module defines a PydanticAI agent that takes the raw text of the
          AI HLEG "Ethics Guidelines for Trustworthy AI" and extracts the
          seven requirements of Trustworthy AI in a structured form, including
          optional RequirementSubtopics under each requirement.

          TRUSTWORTHINESS PRINCIPLES:

            - The agent ONLY performs semantic extraction.
              It does NOT write to Neo4j or perform any side effects.

            - All deterministic metadata (document_id, source_file, year, etc.)
              is provided via HlegPreprocessDeps and MUST be echoed back exactly.

            - The set of requirements is CLOSED and CANONICAL:
              exactly seven requirements, with predefined IDs and names.
              The agent must not invent new requirements.

            - RequirementSubtopics are optional titled sub-sections under a
              single requirement (e.g. 'Sustainable and environmentally "
              "friendly AI', 'Social impact', 'Society and Democracy').
              They are NOT new requirements; they refine one requirement.

            - The 'full_text' and 'description' fields must be grounded in the
              original guidelines text (verbatim or lightly cleaned), not invented.
          """

          from dotenv import load_dotenv
          from pydantic_ai import Agent
          from pydantic_ai.models.openai import OpenAIChatModel

          from models.ai_hleg import HlegStructuredDoc
          from models.hleg_preprocess import HlegPreprocessDeps

          # Load environment variables from .env file (for OPENAI_API_KEY)
          load_dotenv()

          # ============================================================================
          # LLM Model Configuration
          # ============================================================================

          # Use GPT-5-nano for high-context, cost-effective preprocessing
          model = OpenAIChatModel(
              model_name="gpt-5-nano",
          )


          # ============================================================================
          # Preprocessing Agent Definition
          # ============================================================================

          hleg_preprocess_agent = Agent[HlegPreprocessDeps, HlegStructuredDoc](
              model,
              deps_type=HlegPreprocessDeps,
              output_type=HlegStructuredDoc,
              instructions="""
              You are a preprocessing specialist for the AI HLEG 'Ethics Guidelines
              for Trustworthy AI'.

              Your task is to read the ENTIRE guidelines text and extract a
              structured representation of the SEVEN requirements of Trustworthy AI,
              plus optional RequirementSubtopics under each requirement when the
              text clearly has titled sub-headings.

              INPUT:
                - Full plain text of the AI HLEG guidelines
                - Deterministic metadata via deps:
                    * document_id (e.g. 'ai_hleg_2019')
                    * source_file (e.g. 'data/ai_hleg.txt')
                    * jurisdiction (e.g. 'EU')
                    * instrument_type (e.g. 'Guidelines')
                    * year (e.g. 2019)

              OUTPUT:
                - One HlegStructuredDoc with:
                    * document_id, official_title, short_title, year
                    * requirements: exactly SEVEN HlegRequirement objects
                      (each may have zero or more RequirementSubtopics)

              CRITICAL RULES:

              1. METADATA HANDLING
                 - Echo document_id, year, etc. exactly from deps.
                 - Do NOT infer or change these values.
                 - If the official title appears in the text, copy it faithfully
                   into 'official_title'. You may set 'short_title' to a concise
                   variant like 'AI HLEG Ethics Guidelines'.

              2. CLOSED SET OF REQUIREMENTS
                 The seven requirements of Trustworthy AI are:

                   1) Human agency and oversight
                   2) Technical robustness and safety
                   3) Privacy and data governance
                   4) Transparency
                   5) Diversity, non-discrimination and fairness
                   6) Societal and environmental well-being
                   7) Accountability

                 You MUST:
                   - Extract exactly these seven requirements, no more, no less.
                   - Use the following stable IDs for the 'id' field:

                     - human_agency_and_oversight
                     - technical_robustness_and_safety
                     - privacy_and_data_governance
                     - transparency
                     - diversity_non_discrimination_and_fairness
                     - societal_and_environmental_well_being
                     - accountability

                   - The 'name' field must match the official wording in the guidelines
                     as closely as possible (minor punctuation differences are OK).

              3. SHORT_DESCRIPTION vs FULL_TEXT
                 - short_description:
                     * 1–3 sentences summarising the requirement.
                     * Must be faithful to the guidelines and NOT speculative.
                     * You may paraphrase as long as the meaning is preserved.

                 - full_text:
                     * Use a substantial excerpt from the guidelines section that
                       introduces and explains the requirement.
                     * You may remove line breaks, bullets, and minor formatting,
                       but must NOT invent content.
                     * The goal is to have a grounded text we can later show to users
                       and use for alignment with EU AI Act and incidents.

              4. REQUIREMENTSUBTOPICS
                 - Some requirements have clearly titled sub-sections/aspects, such as:
                     * "Sustainable and environmentally friendly AI"
                     * "Social impact"
                     * "Society and Democracy"
                   under the requirement "Societal and environmental well-being".

                 - For such cases, you SHOULD create RequirementSubtopics, where:
                     * subtopic.id is a stable snake_case identifier derived from
                       the requirement id and the heading, e.g.:
                         'societal_env_wellbeing_sustainable_ai',
                         'societal_env_wellbeing_social_impact',
                         'societal_env_wellbeing_society_and_democracy'.
                     * subtopic.label is the heading text (cleaned).
                     * subtopic.description is the full paragraph(s) under that heading,
                       cleaned of extraneous whitespace but grounded in the original text.

                 - Only create subtopics when there is a clear, explicit heading
                   or strong thematic separation in the text.
                 - Do NOT treat subtopics as new requirements. They are aspects of
                   a single requirement.

              5. RELATED PRINCIPLES
                 - Optionally, you may fill 'related_principles' with IDs of the
                   HLEG ethical principles that underpin the requirement.
                 - These principle IDs (for future expansion) should be:

                     - respect_for_human_autonomy
                     - prevention_of_harm
                     - fairness
                     - explicability

                 - If you're not sure, leave 'related_principles' empty.
                   Do NOT invent new principle IDs.

              6. TAGS
                 - 'tags' is optional. You may provide 0–5 concise keywords
                   per requirement to help future querying, e.g.:

                     - For technical robustness and safety:
                         ['safety', 'robustness', 'reliability']
                     - For diversity, non-discrimination and fairness:
                         ['bias', 'non-discrimination']

                 - Tags must be grounded in the content of the requirement.

              7. COMPLETENESS & FAITHFULNESS
                 - You must extract ALL seven requirements.
                 - Do NOT drop any requirement.
                 - Do NOT add extra requirements beyond the canonical seven.
                 - All text fields must be grounded in the original document.

              8. OUTPUT STYLE
                 - Produce a single HlegStructuredDoc object.
                 - No extra commentary or free-form text outside the structured output.
                 - This output will be validated by Pydantic; follow the schema precisely.
              """,
          )

      - path: ingest_hleg.py
        type: update
        content: |
          """
          Deterministic Neo4j Ingestion for AI HLEG Requirements

          This module takes a HlegStructuredDoc (output from agent_hleg_preprocess.py)
          and writes it to Neo4j.

          Key principles:
            - NO LLM calls here - all data comes from HlegStructuredDoc.
            - Deterministic and idempotent:
                * Uses MERGE for HLEG document node, requirement nodes,
                  and requirement subtopic nodes.
                * MERGE for relationships to avoid duplicates.
            - Simple, explicit graph schema:

                (h:HLEG {document_id})
                  -[:HAS_REQUIREMENT]->
                (r:HLEGRequirement {id})
                  -[:HAS_SUBTOPIC]->
                (s:HLEGRequirementSubtopic {id})

          This mirrors the deterministic ingestion pattern used for the EU AI Act.
          """

          from typing import List

          from neo4j import Driver
          from models.ai_hleg import (
              HlegStructuredDoc,
              HlegRequirement,
              HlegRequirementSubtopic,
          )
          from config.neo4j_config import get_neo4j_driver


          def ingest_hleg_document(doc: HlegStructuredDoc) -> None:
              """
              Ingest a HlegStructuredDoc into Neo4j in a deterministic way.

              Graph schema:

                - (h:HLEG {document_id})
                    * h.official_title
                    * h.short_title
                    * h.year

                - (r:HLEGRequirement {id})
                    * r.order
                    * r.name
                    * r.short_description
                    * r.full_text
                    * r.related_principles (array)
                    * r.tags (array)

                - (s:HLEGRequirementSubtopic {id})
                    * s.label
                    * s.description

                - (h)-[:HAS_REQUIREMENT]->(r)
                - (r)-[:HAS_SUBTOPIC]->(s)

              Args:
                  doc: The HlegStructuredDoc produced by the preprocessing agent.
              """
              with get_neo4j_driver() as driver:
                  _create_hleg_document_and_requirements(driver, doc)

              print(f"✓ Ingested HLEG document '{doc.document_id}' to Neo4j")
              print(f"  - Requirements: {len(doc.requirements)}")


          def _create_hleg_document_and_requirements(driver: Driver, doc: HlegStructuredDoc) -> None:
              """
              Create or merge the HLEG document node, its requirements, and subtopics.
              """
              # Step 1: Create/merge HLEG document node
              cypher_doc = """
              MERGE (h:HLEG {document_id: $document_id})
              SET h.official_title = $official_title,
                  h.short_title    = $short_title,
                  h.year           = $year
              """
              driver.execute_query(
                  cypher_doc,
                  document_id=doc.document_id,
                  official_title=doc.official_title,
                  short_title=doc.short_title,
                  year=doc.year,
              )

              # Step 2: Create/merge requirement nodes and :HAS_REQUIREMENT relationships
              #         plus RequirementSubtopics and :HAS_SUBTOPIC relationships.
              cypher_req = """
              MATCH (h:HLEG {document_id: $document_id})
              UNWIND $requirements AS req
              MERGE (r:HLEGRequirement {id: req.id})
              SET r.order             = req.order,
                  r.name              = req.name,
                  r.short_description = req.short_description,
                  r.full_text         = req.full_text,
                  r.related_principles = req.related_principles,
                  r.tags               = req.tags
              MERGE (h)-[:HAS_REQUIREMENT]->(r)

              // Handle subtopics (if any) for this requirement
              FOREACH (sub IN req.subtopics |
                MERGE (s:HLEGRequirementSubtopic {id: sub.id})
                SET s.label       = sub.label,
                    s.description = sub.description
                MERGE (r)-[:HAS_SUBTOPIC]->(s)
              )
              """

              requirements_data: List[dict] = []
              for r in doc.requirements:
                  subtopics_data: List[dict] = [
                      {
                          "id": s.id,
                          "label": s.label,
                          "description": s.description,
                      }
                      for s in r.subtopics
                  ]
                  requirements_data.append(
                      {
                          "id": r.id,
                          "order": r.order,
                          "name": r.name,
                          "short_description": r.short_description,
                          "full_text": r.full_text,
                          "related_principles": r.related_principles,
                          "tags": r.tags,
                          "subtopics": subtopics_data,
                      }
                  )

              driver.execute_query(
                  cypher_req,
                  document_id=doc.document_id,
                  requirements=requirements_data,
              )
